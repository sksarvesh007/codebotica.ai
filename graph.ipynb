{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq6o3wdPR6yu",
        "outputId": "d30f6b0d-1e7d-44e7-deba-0fb7a8508bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.3/221.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -U langchain_community tiktoken langchain-cohere langchainhub chromadb langchain langgraph  tavily-python langchain_groq langchain_google_genai --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4K_pf1OSahK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfFN22jeS7V3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "langchain_api_key =userdata.get(\"LANGSMITH_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Onmy7fjS_80",
        "outputId": "b0fc622d-c67b-4dfd-91fd-4839a670a586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model retrieved\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    temperature=0,\n",
        "    max_tokens=2048,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    groq_api_key = groq_api_key\n",
        ")\n",
        "print(\"model retrieved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLNENYv4Vqh2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "class domainrouter(BaseModel):\n",
        "    proj_domain: str = Field(\n",
        "        description=\"answer with the domain in which the project lies in , whether in 'webapp' , 'blockchain' , 'mobile' , 'aiml' , 'backend'. Return only the domain name only \"\n",
        "    )\n",
        "\n",
        "structured_llm_grader = llm.with_structured_output(domainrouter)\n",
        "system = \"\"\"\n",
        "\"\"\"\n",
        "route_domain = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} \"),\n",
        "    ]\n",
        ")\n",
        "domain_router = route_domain | structured_llm_grader\n",
        "query = \"make a restaurant website with only text in it no images , give it a table as well of dishes with price\"\n",
        "proj_domain = domain_router.invoke({\"query\": query})\n",
        "domain = proj_domain.proj_domain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Go1-hMWqiZ",
        "outputId": "8a0b74c0-cb37-47cb-dc53-3347ab2b7d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "webapp\n"
          ]
        }
      ],
      "source": [
        "print(domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXp8Qs78qlSu",
        "outputId": "89451fcd-5c98-4aa3-8446-2a1e34c46761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleHTML\n"
          ]
        }
      ],
      "source": [
        "from re import template\n",
        "class templaterouter(BaseModel):\n",
        "    structure_template: str = Field(\n",
        "        description=\"decide which template is to be used to make the skeleton codebase of the project , the project domain will be provided. If the domain is 'webapp' you need to classify the template into 'angular', 'NextJS' , 'Astro' , 'REACT_Javascript' , 'REACT_typescript' , 'Simple' , 'Svelte' . If the project domain is Backend development then classify the project into 'Go' , 'Flask' , 'Node' , 'Rust' , 'Laravel' , 'Django' . If the domain is in 'mobile' then classify the project into these templates 'Flutter' , 'react-native' . If the project domain is 'aiml' then classify the project with 'Langchain' . if the domain is 'blockchain' then just simply return 'nil'\"\n",
        "    )\n",
        "\n",
        "structured_llm_grader = llm.with_structured_output(templaterouter)\n",
        "system = \"\"\"You are a professional software developer who has an expertise in the web development , blockchain , aiml and mobile development role ,\n",
        "    you are extremely specialised in creating the codebases of the complex projects and know which pre existing template to use for various projects , We currently have these templates in the 'webapp' domain which are\n",
        "     'angular', 'NextJS' , 'Astro' , 'REACT_Javascript' , 'REACT_typescript' , 'SimpleHTML' , 'Svelte' , 'Flask' (Note that if someone wants a website in python you are supposed to return 'Flask') . In the 'backend' domain we have 'Go' , 'Flask' , 'Node' , 'Rust' , 'Laravel' , 'Django' templates . In the 'mobile' domain in which we have to app development we have 'Flutter' , 'react-native' templates . If the domain is AIML , then we have 'langchain' as the domain\n",
        "     Carefully return me with the project template only on the basis of the domain and the project details. Dont ever return with the domain name , only return the existing templates which are listed in each domain\n",
        "     Dont return 'webapp' , 'aiml' , 'backend' , 'mobile'. Also if not given which template to use in the user project details then you have to return the most basic template which requires most less files to make\n",
        "     You are supposed to only return with the listed templates only and only ,dont return anything else than the templates which are listed here \"\"\"\n",
        "template_domain = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} , domain : {domain}\"),\n",
        "    ])\n",
        "template_router = template_domain | structured_llm_grader\n",
        "template = template_router.invoke({\"query\": query , \"domain\": domain})\n",
        "template_structure = template.structure_template\n",
        "print(template_structure)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaADYr62VhbF",
        "outputId": "28c4e7c4-f932-4e2d-bf99-1240f6cb6da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Design a text-based restaurant website with a table displaying dishes and their corresponding prices, excluding images and focusing on a simple, functional layout.\n"
          ]
        }
      ],
      "source": [
        "from types import new_class\n",
        "class queryreframer(BaseModel):\n",
        "    new_query: str = Field(\n",
        "        description = \"You a question re-writer that converts an input question to a better version that is optimized and does not looses any of he context \"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(queryreframer)\n",
        "system = \"\"\"\n",
        "You are a professional at reframing the user inputs without loosing the context and the meaning of the query , make changes in the query such that its relevant to the coding project making , make the query such that its relevant to a model which makes projects on the basis of the user queries . Dont make it more complex than it was , and dont add any kind of new functionalities , also dont include user authentication unless stated in the project detail\n",
        "Return the functionalities as well of the project\"\"\"\n",
        "query_reframing = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"query : {query}\"),\n",
        "    ]\n",
        ")\n",
        "query_reframer = query_reframing | structured_llm_grader\n",
        "new_query_init = query_reframer.invoke({\"query\": query})\n",
        "new_query = new_query_init.new_query\n",
        "print(new_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lkg5oi2m35i",
        "outputId": "d31884fa-73b8-47fd-9d59-98cd4086fbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "template_compatibility='yes'\n"
          ]
        }
      ],
      "source": [
        "class templatechecker(BaseModel):\n",
        "    template_compatibility : str = Field(\n",
        "        description = \"Check whether the given user query can be made with the template given , return 'yes' or 'no' . \"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(templatechecker)\n",
        "system = \"\"\"You are a professional software developer , you are expert at checking whether the project query given by the user can be made from the template , Return 'yes' if the template is correct and 'no' if the template is incorrect\"\"\"\n",
        "template_checking = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"query : {query} , template : {template}\"),\n",
        "    ]\n",
        ")\n",
        "template_checker = template_checking | structured_llm_grader\n",
        "print(template_checker.invoke({\"query\": query , \"template\": template_structure}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC8Qlh_Edtxl",
        "outputId": "33277b8c-6db9-4eac-84e0-1a5774c9a617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pulse\n"
          ]
        }
      ],
      "source": [
        "class directorynamer(BaseModel):\n",
        "    proj_name : str = Field(\n",
        "        description = \"Give the appropriate name for the project\"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(directorynamer)\n",
        "system = \"\"\"\n",
        "You are a professional software developer and are extremely professional at giving names to the projects . You have to name the project based on the domain , and the project details . Dont include the domain name in the title , make the title more creative and of single word only \"\"\"\n",
        "directory_naming = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} , domain : {domain}\"),\n",
        "    ]\n",
        ")\n",
        "directory_namer = directory_naming | structured_llm_grader\n",
        "project_name = directory_namer.invoke({\"query\": query , \"domain\": domain})\n",
        "root_dir = project_name.proj_name\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnFnSfrjRhDq",
        "outputId": "331ea12d-6560-4e4c-df82-e23004ae85f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TastyText\n"
          ]
        }
      ],
      "source": [
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwhhAqn4PhG2",
        "outputId": "831999c6-63e5-41cd-8158-a0e8ed301ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleHTML\n"
          ]
        }
      ],
      "source": [
        "print(template_structure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpRChJY5PThN"
      },
      "outputs": [],
      "source": [
        "from code_templates.webapp.simple_html import simple_html_template\n",
        "from code_templates.webapp.react_js_template import react_js_app_template\n",
        "from code_templates.webapp.react_ts_template import react_ts_app_template\n",
        "from code_templates.webapp.flask_app import generate_flask_template\n",
        "def templatemaker(template_structure , root_dir ):\n",
        "  if template_structure == \"SimpleHTML\":\n",
        "    simple_html_template(root_dir)\n",
        "  if template_structure == \"REACT_Javascript\":\n",
        "    react_js_app_template(root_dir)\n",
        "  if template_structure == \"Flask\":\n",
        "    generate_flask_template(root_dir)\n",
        "  if template_structure=='REACT_typescript':\n",
        "    react_ts_app_template(root_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kypyoxRPuzT",
        "outputId": "2684f8b4-9d95-4da5-e2fb-fdb206a1a809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project 'Pulse' created successfully!\n"
          ]
        }
      ],
      "source": [
        "templatemaker(template_structure , root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1TT8xeCP2_K",
        "outputId": "eb7c6dbf-86f2-458a-fff2-4f624028f625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Pulse/style.css', 'Pulse/README.md', 'Pulse/index.html', 'Pulse/script.js']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def get_all_files(directory):\n",
        "    files_list = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            files_list.append(file_path)\n",
        "\n",
        "    return files_list\n",
        "all_files = get_all_files(root_dir)\n",
        "print(all_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGdu5OoAbI0o",
        "outputId": "37c97ab5-5d92-487f-b562-cc3011ca0322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Pulse/data.csv', 'Pulse/requirements.txt']\n"
          ]
        }
      ],
      "source": [
        "class extrafiles(BaseModel):\n",
        "    extra_files : list = Field(\n",
        "        description = \"Give the extra files required in the project apart from the listed files in python List format\"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(extrafiles)\n",
        "system = \"\"\"\n",
        "You are a professional software developer and are extremely professional at listing the appropriate files required to make the project. You have to basically list the files which are required in the projects but are not listed in the file directory .\n",
        "You also have to recognise the file structure accordingly . You also have the functionalities to add new folder if and only if required . List the extra files required in the python List format . The user input and the list of the existing files are given\n",
        "Do not ever make duplicate files , and please just try to make the most minimal extra files possible so that its easy for the user. Return an empty list if all the necessary files are already there .\n",
        "Ignore the license and icon files\"\"\"\n",
        "extra_filing = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} , domain : {domain} , List of existing files : {existing_files}\"),\n",
        "    ]\n",
        ")\n",
        "extra_file_lister = extra_filing | structured_llm_grader\n",
        "project_name = extra_file_lister.invoke({\"query\": new_query , \"domain\": domain , \"existing_files\": all_files})\n",
        "extra_files = project_name.extra_files\n",
        "print(extra_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smXKIF5szgeu",
        "outputId": "fd783188-f32d-4cdb-bbe6-612c5f4c5428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Pulse/style.css', 'Pulse/README.md', 'Pulse/index.html', 'Pulse/script.js', 'Pulse/data.csv', 'Pulse/requirements.txt']\n"
          ]
        }
      ],
      "source": [
        "#now append extra_files list and all_files into a new list\n",
        "final_files = all_files + extra_files\n",
        "print(final_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmMYRF8ohMjU",
        "outputId": "6be3498c-180a-46ff-c3c1-9a1a72bd2fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Pulse/style.css', 'Pulse/README.md', 'Pulse/index.html', 'Pulse/script.js', 'Pulse/data.csv', 'Pulse/requirements.txt']\n"
          ]
        }
      ],
      "source": [
        "# remove the .png files from this\n",
        "final_files = [file for file in final_files if not file.endswith('.png')]\n",
        "print(final_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h_k4nHIhH69"
      },
      "outputs": [],
      "source": [
        "class CodeGeneration(BaseModel):\n",
        "    generated_code: dict = Field(\n",
        "        description=\"Return the generated code for the corresponding file in JSON format. The keys are the file names and the values are the code content.\"\n",
        "    )\n",
        "\n",
        "system = \"\"\"\n",
        "You are a highly proficient code generator agent with expertise in various programming languages and domains. Your task is to generate the appropriate code for a given file in a project based on the project description, domain, and file name.\n",
        "You are provided the project details, the domain, and the current file structure.\n",
        "You must only return the code that should go inside the provided file name and output it in JSON format.\n",
        "Do not include any explanations, only return the code in JSON format with the file name as the key and the generated code as the value.\n",
        "\"\"\"\n",
        "code_generation_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Project details: {query}, Domain: {domain}, Existing files: {existing_files}, File to generate code for: {file_name}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "structured_llm_grader = llm.with_structured_output(CodeGeneration)\n",
        "def generate_code(query, domain, all_files, file_name):\n",
        "    result = code_generation_prompt | structured_llm_grader\n",
        "    code_gen = result.invoke({\n",
        "        \"query\": query,\n",
        "        \"domain\": domain,\n",
        "        \"existing_files\": all_files,\n",
        "        \"file_name\": file_name\n",
        "    })\n",
        "\n",
        "    return code_gen.generated_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEI1cew7nZTZ"
      },
      "outputs": [],
      "source": [
        "def generate_and_write_code(query, domain, all_files):\n",
        "    for file_path in final_files:\n",
        "        file_name = os.path.basename(file_path)\n",
        "\n",
        "        generated_code = generate_code(query, domain, all_files, file_name)\n",
        "        code = generated_code.get(file_name, \"\")\n",
        "\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write(code.replace(\"\\\\n\", \"\\n\"))\n",
        "\n",
        "        print(f\"Generated and wrote code for {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4Z3k9yCn70t",
        "outputId": "284bff54-70da-4255-9429-ec6136bfa4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated and wrote code for style.css\n",
            "Generated and wrote code for README.md\n",
            "Generated and wrote code for index.html\n",
            "Generated and wrote code for script.js\n",
            "Generated and wrote code for data.csv\n",
            "Generated and wrote code for requirements.txt\n"
          ]
        }
      ],
      "source": [
        "generate_and_write_code(new_query, domain,final_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8nj3Vj-BoINL",
        "outputId": "a0fcd08d-fa02-4346-d5f7-ae3fb7897dea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Pulse.zip'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#now make a downloadable zip file of the folder Typemonk\n",
        "import shutil\n",
        "shutil.make_archive(root_dir, 'zip', root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLDc0QJDm7dN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}