{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq6o3wdPR6yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a149e0dd-91d5-4eb3-e519-d82183d301ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m61.4/67.3 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m781.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.2/210.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.4/93.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install -U langchain_community tiktoken langchain-cohere langchainhub chromadb langchain langgraph  tavily-python langchain_groq langchain_google_genai --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4K_pf1OSahK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfFN22jeS7V3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "langchain_api_key =userdata.get(\"LANGSMITH_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Onmy7fjS_80",
        "outputId": "cc85c82d-c0c6-414e-cb36-57bcdf82104e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model retrieved\n"
          ]
        }
      ],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-70b-versatile\",\n",
        "    temperature=0,\n",
        "    max_tokens=2048,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    groq_api_key = groq_api_key\n",
        ")\n",
        "print(\"model retrieved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLNENYv4Vqh2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "class domainrouter(BaseModel):\n",
        "    proj_domain: str = Field(\n",
        "        description=\"answer with the domain in which the project lies in , whether in 'webapp' , 'blockchain' , 'mobile' , 'aiml' , 'backend'. Return only the domain name only \"\n",
        "    )\n",
        "\n",
        "structured_llm_grader = llm.with_structured_output(domainrouter)\n",
        "system = \"\"\"You are a professional software developer who has an expertise in the web development ,backend ,  blockchain , aiml and mobile development role ,\n",
        "    you need to classify whether the project details given by the user lies in which domain , whether it's related to website development , in this case return 'webapp' ,or the project is of backend then return 'backend' or the project is for the blockchain domain and in this case return 'blockchain'\n",
        "    whether the project is related to AIML then return with the 'aiml' domain , or else if the project contains app development then return with the 'mobile'.\n",
        "    remember that this decision is very crucial dont give any kind of wrong answer. If the website making or app making is required in aiml or blockchain domain , then categorize them into 'webapp' or 'mobile' only \"\"\"\n",
        "route_domain = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} \"),\n",
        "    ]\n",
        ")\n",
        "domain_router = route_domain | structured_llm_grader\n",
        "query = \"make me a AAPL stocks dashboard with more than 3 graphs in flask , it should be well detailed \"\n",
        "proj_domain = domain_router.invoke({\"query\": query})\n",
        "domain = proj_domain.proj_domain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Go1-hMWqiZ",
        "outputId": "066fdc25-de1e-4883-9fea-debedf0985be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "webapp\n"
          ]
        }
      ],
      "source": [
        "print(domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXp8Qs78qlSu",
        "outputId": "531aa6e8-4c75-4646-d28c-1f7e1e0b898e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask\n"
          ]
        }
      ],
      "source": [
        "from re import template\n",
        "class templaterouter(BaseModel):\n",
        "    structure_template: str = Field(\n",
        "        description=\"decide which template is to be used to make the skeleton codebase of the project , the project domain will be provided. If the domain is 'webapp' you need to classify the template into 'angular', 'NextJS' , 'Astro' , 'REACT_Javascript' , 'REACT_typescript' , 'Simple' , 'Svelte' . If the project domain is Backend development then classify the project into 'Go' , 'Flask' , 'Node' , 'Rust' , 'Laravel' , 'Django' . If the domain is in 'mobile' then classify the project into these templates 'Flutter' , 'react-native' . If the project domain is 'aiml' then classify the project with 'Langchain' . if the domain is 'blockchain' then just simply return 'nil'\"\n",
        "    )\n",
        "\n",
        "structured_llm_grader = llm.with_structured_output(templaterouter)\n",
        "system = \"\"\"You are a professional software developer who has an expertise in the web development , blockchain , aiml and mobile development role ,\n",
        "    you are extremely specialised in creating the codebases of the complex projects and know which pre existing template to use for various projects , We currently have these templates in the 'webapp' domain which are\n",
        "     'angular', 'NextJS' , 'Astro' , 'REACT_Javascript' , 'REACT_typescript' , 'SimpleHTML' , 'Svelte' , 'Flask' (Note that if someone wants a website in python you are supposed to return 'Flask') . In the 'backend' domain we have 'Go' , 'Flask' , 'Node' , 'Rust' , 'Laravel' , 'Django' templates . In the 'mobile' domain in which we have to app development we have 'Flutter' , 'react-native' templates . If the domain is AIML , then we have 'langchain' as the domain\n",
        "     Carefully return me with the project template only on the basis of the domain and the project details. Dont ever return with the domain name , only return the existing templates which are listed in each domain\n",
        "     Dont return 'webapp' , 'aiml' , 'backend' , 'mobile'. Also if not given which template to use in the user project details then you have to return the most basic template which requires most less files to make \"\"\"\n",
        "template_domain = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} , domain : {domain}\"),\n",
        "    ])\n",
        "template_router = template_domain | structured_llm_grader\n",
        "template = template_router.invoke({\"query\": query , \"domain\": domain})\n",
        "template_structure = template.structure_template\n",
        "print(template_structure)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaADYr62VhbF",
        "outputId": "0f8186ae-ccbe-41bd-a275-f8d979417943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create a comprehensive AAPL stocks dashboard using Flask, incorporating more than 3 detailed graphs to display various stock metrics and trends, without adding new functionalities or user authentication.\n"
          ]
        }
      ],
      "source": [
        "from types import new_class\n",
        "class queryreframer(BaseModel):\n",
        "    new_query: str = Field(\n",
        "        description = \"You a question re-writer that converts an input question to a better version that is optimized and does not looses any of he context \"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(queryreframer)\n",
        "system = \"\"\"\n",
        "You are a professional at reframing the user inputs without loosing the context and the meaning of the query , make changes in the query such that its relevant to the coding project making , make the query such that its relevant to a model which makes projects on the basis of the user queries . Dont make it more complex than it was , and dont add any kind of new functionalities , also dont include user authentication unless stated in the project detail\n",
        "Return the functionalities as well of the project\"\"\"\n",
        "query_reframing = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"query : {query}\"),\n",
        "    ]\n",
        ")\n",
        "query_reframer = query_reframing | structured_llm_grader\n",
        "new_query_init = query_reframer.invoke({\"query\": query})\n",
        "new_query = new_query_init.new_query\n",
        "print(new_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lkg5oi2m35i",
        "outputId": "96aaae95-80b3-4f40-ea9e-550cf9331c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "template_compatibility='yes'\n"
          ]
        }
      ],
      "source": [
        "class templatechecker(BaseModel):\n",
        "    template_compatibility : str = Field(\n",
        "        description = \"Check whether the given user query can be made with the template given , return 'yes' or 'no' . \"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(templatechecker)\n",
        "system = \"\"\"You are a professional software developer , you are expert at checking whether the project query given by the user can be made from the template , Return 'yes' if the template is correct and 'no' if the template is incorrect\"\"\"\n",
        "template_checking = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"query : {query} , template : {template}\"),\n",
        "    ]\n",
        ")\n",
        "template_checker = template_checking | structured_llm_grader\n",
        "print(template_checker.invoke({\"query\": query , \"template\": template_structure}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC8Qlh_Edtxl",
        "outputId": "cdb7c91f-2240-4f75-c53b-0c196ecd8cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StockSpectra\n"
          ]
        }
      ],
      "source": [
        "class directorynamer(BaseModel):\n",
        "    proj_name : str = Field(\n",
        "        description = \"Give the appropriate name for the project\"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(directorynamer)\n",
        "system = \"\"\"\n",
        "You are a professional software developer and are extremely professional at giving names to the projects . You have to name the project based on the domain , and the project details . Dont include the domain name in the title , make the title more creative and of single word only \"\"\"\n",
        "directory_naming = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} , domain : {domain}\"),\n",
        "    ]\n",
        ")\n",
        "directory_namer = directory_naming | structured_llm_grader\n",
        "project_name = directory_namer.invoke({\"query\": query , \"domain\": domain})\n",
        "root_dir = project_name.proj_name\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnFnSfrjRhDq",
        "outputId": "666da989-3fdc-435a-c9df-4cfb6e791ca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StockSpectra\n"
          ]
        }
      ],
      "source": [
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwhhAqn4PhG2",
        "outputId": "df9935d1-e0df-4e72-b7a8-804ca20df624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask\n"
          ]
        }
      ],
      "source": [
        "print(template_structure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpRChJY5PThN"
      },
      "outputs": [],
      "source": [
        "from code_templates.webapp.simple_html import simple_html_template\n",
        "from code_templates.webapp.react_js_template import react_js_app_template\n",
        "from code_templates.webapp.react_ts_template import react_ts_app_template\n",
        "from code_templates.webapp.flask_app import generate_flask_template\n",
        "def templatemaker(template_structure , root_dir ):\n",
        "  if template_structure == \"SimpleHTML\":\n",
        "    simple_html_template(root_dir)\n",
        "  if template_structure == \"REACT_Javascript\":\n",
        "    react_js_app_template(root_dir)\n",
        "  if template_structure == \"Flask\":\n",
        "    generate_flask_template(root_dir)\n",
        "  if template_structure=='REACT_typescript':\n",
        "    react_ts_app_template(root_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kypyoxRPuzT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb84958-bd93-4276-c9bd-a2686cef293d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask project template created in 'StockSpectra'\n"
          ]
        }
      ],
      "source": [
        "templatemaker(template_structure , root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1TT8xeCP2_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aeb5537-a263-46e9-d048-1c70dde0372d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['StockSpectra/README.md', 'StockSpectra/requirements.txt', 'StockSpectra/app/app.py', 'StockSpectra/app/templates/index.html', 'StockSpectra/app/static/style.css', 'StockSpectra/app/static/main.js']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def get_all_files(directory):\n",
        "    files_list = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            files_list.append(file_path)\n",
        "\n",
        "    return files_list\n",
        "all_files = get_all_files(root_dir)\n",
        "print(all_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class extrafiles(BaseModel):\n",
        "    extra_files : list = Field(\n",
        "        description = \"Give the extra files required in the project apart from the listed files in python List format\"\n",
        "    )\n",
        "structured_llm_grader = llm.with_structured_output(extrafiles)\n",
        "system = \"\"\"\n",
        "You are a professional software developer and are extremely professional at listing the appropriate files required to make the project. You have to basically list the files which are required in the projects but are not listed in the file directory .\n",
        "You also have to recognise the file structure accordingly . You also have the functionalities to add new folder if and only if required . List the extra files required in the python List format . The user input and the list of the existing files are given\n",
        "Do not ever make duplicate files , and please just try to make the most minimal extra files possible so that its easy for the user. Return an empty list if all the necessary files are already there .\n",
        "Ignore the license and icon files\"\"\"\n",
        "extra_filing = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"project details : {query} , domain : {domain} , List of existing files : {existing_files}\"),\n",
        "    ]\n",
        ")\n",
        "extra_file_lister = extra_filing | structured_llm_grader\n",
        "project_name = extra_file_lister.invoke({\"query\": new_query , \"domain\": domain , \"existing_files\": all_files})\n",
        "extra_files = project_name.extra_files\n",
        "print(extra_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGdu5OoAbI0o",
        "outputId": "94bae05d-511a-4be1-c2b1-32b78f1b5328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['StockSpectra/app/templates/about.html', 'StockSpectra/app/templates/contact.html', 'StockSpectra/app/static/data.csv', 'StockSpectra/app/static/images/aapl_logo.png', 'StockSpectra/app/templates/graphs.html', 'StockSpectra/app/static/js/d3.js', 'StockSpectra/app/static/js/c3.js', 'StockSpectra/app/templates/stock_info.html', 'StockSpectra/app/static/js/plotly.js', 'StockSpectra/app/templates/compare.html']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now append extra_files list and all_files into a new list\n",
        "final_files = all_files + extra_files\n",
        "print(final_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smXKIF5szgeu",
        "outputId": "9a660fe7-afc5-4a7a-e255-d132e167a5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['StockSpectra/README.md', 'StockSpectra/requirements.txt', 'StockSpectra/app/app.py', 'StockSpectra/app/templates/index.html', 'StockSpectra/app/static/style.css', 'StockSpectra/app/static/main.js', 'StockSpectra/app/templates/about.html', 'StockSpectra/app/templates/contact.html', 'StockSpectra/app/static/data.csv', 'StockSpectra/app/static/images/aapl_logo.png', 'StockSpectra/app/templates/graphs.html', 'StockSpectra/app/static/js/d3.js', 'StockSpectra/app/static/js/c3.js', 'StockSpectra/app/templates/stock_info.html', 'StockSpectra/app/static/js/plotly.js', 'StockSpectra/app/templates/compare.html']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_files[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgjP_2R3jS0f",
        "outputId": "8bd2e8df-02cd-46fa-d92e-700529e6ef7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StockSpectra/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filer_name = final_files[0]"
      ],
      "metadata": {
        "id": "4E1tinShjjMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeGeneration(BaseModel):\n",
        "    generated_code: dict = Field(\n",
        "        description=\"Return the generated code for the corresponding file in JSON format. The keys are the file names and the values are the code content.\"\n",
        "    )\n",
        "\n",
        "# Define the system prompt for code generation\n",
        "system = \"\"\"\n",
        "You are a highly proficient code generator agent with expertise in various programming languages and domains. Your task is to generate the appropriate code for a given file in a project based on the project description, domain, and file name.\n",
        "You are provided the project details, the domain, and the current file structure.\n",
        "You must only return the code that should go inside the provided file name and output it in JSON format.\n",
        "Do not include any explanations, only return the code in JSON format with the file name as the key and the generated code as the value.\n",
        "\"\"\"\n",
        "code_generation_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Project details: {query}, Domain: {domain}, Existing files: {existing_files}, File to generate code for: {file_name}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the structured LLM grader with the output format\n",
        "structured_llm_grader = llm.with_structured_output(CodeGeneration)\n",
        "def generate_code(query, domain, all_files, file_name):\n",
        "    # Invoke the LLM with the structured output\n",
        "    result = code_generation_prompt | structured_llm_grader\n",
        "    code_gen = result.invoke({\n",
        "        \"query\": query,\n",
        "        \"domain\": domain,\n",
        "        \"existing_files\": all_files,\n",
        "        \"file_name\": file_name\n",
        "    })\n",
        "\n",
        "    # Return the generated code in JSON format\n",
        "    return code_gen.generated_code"
      ],
      "metadata": {
        "id": "5h_k4nHIhH69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name =filer_name\n",
        "generated_code = generate_code(query, domain, all_files, file_name)"
      ],
      "metadata": {
        "id": "piEC78_um8ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNcNZxVZnLfA",
        "outputId": "1428ad16-fa0e-4201-8580-d20e9b2a6bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Typemonk/style.css': '/* Global Styles */\\n\\nbody {\\n  font-family: Arial, sans-serif;\\n  background-color: #f0f0f0;\\n  margin: 0;\\n  padding: 0;\\n}\\n\\n/* Container Styles */\\n\\n.container {\\n  max-width: 800px;\\n  margin: 40px auto;\\n  padding: 20px;\\n  background-color: #fff;\\n  border: 1px solid #ddd;\\n  border-radius: 10px;\\n  box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\\n}\\n\\n/* Typing Area Styles */\\n\\ntyping-area {\\n  padding: 20px;\\n  font-size: 24px;\\n  font-weight: bold;\\n  color: #333;\\n}\\n\\ntyping-area input {\\n  width: 100%;\\n  padding: 10px;\\n  font-size: 24px;\\n  font-weight: bold;\\n  color: #333;\\n  border: 1px solid #ccc;\\n}\\n\\ntyping-area input:focus {\\n  outline: none;\\n  border-color: #aaa;\\n}\\n\\n/* Stats Styles */\\n\\n.stats {\\n  margin-top: 20px;\\n  padding: 10px;\\n  background-color: #f7f7f7;\\n  border: 1px solid #ddd;\\n}\\n\\n.stats span {\\n  font-size: 18px;\\n  font-weight: bold;\\n  color: #666;\\n}\\n\\n/* Button Styles */\\n\\nbutton {\\n  padding: 10px 20px;\\n  font-size: 18px;\\n  font-weight: bold;\\n  color: #fff;\\n  background-color: #4CAF50;\\n  border: none;\\n  border-radius: 5px;\\n  cursor: pointer;\\n}\\n\\nbutton:hover {\\n  background-color: #3e8e41;\\n}'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ylU5InnPcO",
        "outputId": "5b622c70-0527-46f2-cc01-b5da76ce846e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Typemonk/style.css',\n",
              " 'Typemonk/scripts.js',\n",
              " 'Typemonk/README.md',\n",
              " 'Typemonk/index.html',\n",
              " 'Typemonk/manifest.json',\n",
              " 'Typemonk/words.txt',\n",
              " 'Typemonk/highscores.json']"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_write_code(query, domain, all_files):\n",
        "    for file_path in final_files:\n",
        "        file_name = os.path.basename(file_path)\n",
        "\n",
        "        generated_code = generate_code(query, domain, all_files, file_name)\n",
        "        code = generated_code.get(file_name, \"\")\n",
        "\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write(code.replace(\"\\\\n\", \"\\n\"))\n",
        "\n",
        "        print(f\"Generated and wrote code for {file_name}\")"
      ],
      "metadata": {
        "id": "vEI1cew7nZTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_write_code(new_query, domain,final_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "D4Z3k9yCn70t",
        "outputId": "28a87f4e-d157-49f0-bfeb-5a1a076b1508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated and wrote code for README.md\n",
            "Generated and wrote code for requirements.txt\n",
            "Generated and wrote code for app.py\n",
            "Generated and wrote code for index.html\n",
            "Generated and wrote code for style.css\n",
            "Generated and wrote code for main.js\n",
            "Generated and wrote code for about.html\n",
            "Generated and wrote code for contact.html\n",
            "Generated and wrote code for data.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'StockSpectra/app/static/images/aapl_logo.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a455e762e06c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_and_write_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-bf3f681b4469>\u001b[0m in \u001b[0;36mgenerate_and_write_code\u001b[0;34m(query, domain, all_files)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'StockSpectra/app/static/images/aapl_logo.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now make a downloadable zip file of the folder Typemonk\n",
        "import shutil\n",
        "shutil.make_archive(root_dir, 'zip', root_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8nj3Vj-BoINL",
        "outputId": "cfe866e7-31eb-4996-e178-e0533c6782ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/StockSpectra.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0J5iOg3pDMM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}